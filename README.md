# **目录**
- [相关资料](#相关资料)
  - [本文相关代码](#本文相关代码)
- [一、概述](#一概述)
  - [1.1 基本概念](#11-基本概念)
  - [1.2 两种处理模型](#12-两种处理模型)
    - [（1）微批处理](#微批处理)  // 修正
    - [（2）持续处理](#持续处理) // 修正
  - [1.3 Structured Streaming和Spark SQL、Spark Streaming关系](#13-structured-streaming和spark-sqlspark-streaming关系)
- [二、编写Structured Streaming程序的基本步骤](#二编写structured-streaming程序的基本步骤)
- [三、输入源](#三输入源)
  - [3.1 File源](#31-file源)
    - [（1）创建程序生成JSON格式的File源测试数据](#创建程序生成json格式的file源测试数据) // 修正
    - [（2）创建程序对数据进行统计](#创建程序对数据进行统计) // 修正
    - [（3）测试运行程序](#测试运行程序) // 修正
    - [（4）处理警告](#处理警告) // # **目录**
- [相关资料](#相关资料)
  - [本文相关代码](#本文相关代码)
- [一、概述](#一概述)
  - [1.1 基本概念](#11-基本概念)
  - [1.2 两种处理模型](#12-两种处理模型)
    - [（1）微批处理](#微批处理)  // 修正
    - [（2）持续处理](#持续处理) // 修正
  - [1.3 Structured Streaming和Spark SQL、Spark Streaming关系](#13-structured-streaming和spark-sqlspark-streaming关系)
- [二、编写Structured Streaming程序的基本步骤](#二编写structured-streaming程序的基本步骤)
- [三、输入源](#三输入源)
  - [3.1 File源](#31-file源)
    - [（1）创建程序生成JSON格式的File源测试数据](#创建程序生成json格式的file源测试数据) // 修正
    - [（2）创建程序对数据进行统计](#创建程序对数据进行统计) // 修正
    - [（3）测试运行程序](#测试运行程序) // 修正
    - [（4）处理警告](#处理警告) // 修正
    - [（5）总结分析](#总结分析) // 修正
  - [3.2 Kafka源](#32-kafka源)
    - [（1）启动Kafka](#启动kafka) // 修正
    - [（2）编写生产者（Producer）程序](#编写生产者producer程序) // 修正
    - [（3）安装Python3的Kafka支持](#安装python3的kafka支持) // 修正
    - [（4）运行生产者程序](#运行生产者程序) // 修正
    - [（5）编写并运行消费者（Consumer）程序](#编写并运行消费者consumer程序) // 修正
      - [方式一](#方式一)
      - [方式二](#方式二)
    - [总结](#总结)
  - [3.3 Socket源](#33-socket源)
  - [3.4 Rate源](#34-rate源)

  - [3.2 Kafka源](#32-kafka源)
    - [（1）启动Kafka](#启动kafka) // 修正
    - [（2）编写生产者（Producer）程序](#编写生产者producer程序) // 修正
    - [（3）安装Python3的Kafka支持](#安装python3的kafka支持) // 修正
    - [（4）运行生产者程序](#运行生产者程序) // 修正
    - [（5）编写并运行消费者（Consumer）程序](#编写并运行消费者consumer程序) // 修正
      - [方式一](#方式一)
      - [方式二](#方式二)
    - [总结](#总结)
  - [3.3 Socket源](#33-socket源)
  - [3.4 Rate源](#34-rate源)



# 相关资料
相关资料内容

# 本文相关代码
本文相关代码内容

# 一、概述
概述内容

## 1.1 基本概念
基本概念内容

## 1.2 两种处理模型
两种处理模型内容

### （1）微批处理
微批处理内容

### （2）持续处理
持续处理内容

## 1.3 Structured Streaming和Spark SQL、Spark Streaming关系
Structured Streaming和Spark SQL、Spark Streaming关系内容

# 二、编写Structured Streaming程序的基本步骤
编写Structured Streaming程序的基本步骤内容

# 三、输入源
输入源内容

## 3.1 File源
File源内容

### （1）创建程序生成JSON格式的File源测试数据
创建程序生成JSON格式的File源测试数据内容

### （2）创建程序对数据进行统计
创建程序对数据进行统计内容

### （3）测试运行程序
测试运行程序内容

### （4）处理警告
处理警告内容

### （5）总结分析
总结分析内容

## 3.2 Kafka源
Kafka源内容

### （1）启动Kafka
启动Kafka内容

### （2）编写生产者（Producer）程序
编写生产者（Producer）程序内容

### （3）安装Python3的Kafka支持
安装Python3的Kafka支持内容

### （4）运行生产者程序
运行生产者程序内容

### （5）编写并运行消费者（Consumer）程序
编写并运行消费者（Consumer）程序内容

#### 方式一
方式一内容

#### 方式二
方式二内容

### 总结
总结内容

## 3.3 Socket源
Socket源内容

## 3.4 Rate源
Rate源内容
